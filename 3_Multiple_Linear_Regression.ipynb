{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++ Multiple Linear Regression ++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good models require multiple regressions in order to address complex problems. More variables or determinants you have, more factors you are considering in the model. \n",
    "\n",
    "## Population multiple regression model looks like: \n",
    "\n",
    "#### Y = beta0 + beta1 *X1 + beta2 *X2 + ............ + betak *Xk + error\n",
    "\n",
    "## Sample multiple regression model:\n",
    "\n",
    "#### y_hat = b0 + b1 *x1 + b2 *x2 + .................... + bk *xk + e\n",
    "\n",
    "#### Here y_hat = predicted value while x1, x2, x3.....xk are the independent variables. \n",
    "\n",
    "### The multiple regression is not about the best fitting line anymore. As the number of DV increase, to more than 2, we cannot visualize the model in 2 Dimension. The end result of the MLR is a good model which ensures  a minimum SSE [Sum of Squares Error]. \n",
    "\n",
    "### We ensure this by increasing the explanatory power of the model by increasing the number of variables. \n",
    "\n",
    "### Logic: SSE is inversely proportional to SSR. If SSE Decreases, the SSR increases and vice-versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted R-Squared. \n",
    "### Statisticians always refer to the Adjusted R-squared measure in comparison to the R-squared measure. \n",
    "### Adjusted R-squared < R-squared\n",
    "### Adjusted R-squared penalises excessive use of variables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import seaborn\n",
    "seaborn.set()         # Add skin to the matplotlib plots. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SAT        GPA  Rand 1,2,3\n",
      "count    84.000000  84.000000   84.000000\n",
      "mean   1845.273810   3.330238    2.059524\n",
      "std     104.530661   0.271617    0.855192\n",
      "min    1634.000000   2.400000    1.000000\n",
      "25%    1772.000000   3.190000    1.000000\n",
      "50%    1846.000000   3.380000    2.000000\n",
      "75%    1934.000000   3.502500    3.000000\n",
      "max    2050.000000   3.810000    3.000000\n",
      "     SAT   GPA  Rand 1,2,3\n",
      "0   1714  2.40           1\n",
      "1   1664  2.52           3\n",
      "2   1760  2.54           3\n",
      "3   1685  2.74           3\n",
      "4   1693  2.83           2\n",
      "5   1670  2.91           1\n",
      "6   1764  3.00           2\n",
      "7   1764  3.00           1\n",
      "8   1792  3.01           2\n",
      "9   1850  3.01           3\n",
      "10  1735  3.02           3\n",
      "11  1775  3.07           2\n",
      "12  1735  3.08           1\n",
      "13  1712  3.08           3\n",
      "14  1773  3.12           2\n",
      "15  1872  3.17           2\n",
      "16  1755  3.17           3\n",
      "17  1674  3.17           2\n",
      "18  1842  3.17           3\n",
      "19  1786  3.19           3\n",
      "20  1761  3.19           3\n",
      "21  1722  3.19           3\n",
      "22  1663  3.20           3\n",
      "23  1687  3.21           1\n",
      "24  1974  3.24           1\n",
      "25  1826  3.28           1\n",
      "26  1787  3.28           1\n",
      "27  1821  3.28           3\n",
      "28  2020  3.28           1\n",
      "29  1794  3.28           2\n",
      "..   ...   ...         ...\n",
      "54  1879  3.44           1\n",
      "55  1887  3.47           1\n",
      "56  1730  3.47           2\n",
      "57  1953  3.47           1\n",
      "58  1781  3.47           2\n",
      "59  1891  3.48           2\n",
      "60  1964  3.49           1\n",
      "61  1808  3.49           3\n",
      "62  1893  3.50           3\n",
      "63  2041  3.51           3\n",
      "64  1893  3.51           1\n",
      "65  1832  3.52           2\n",
      "66  1850  3.52           3\n",
      "67  1934  3.54           2\n",
      "68  1861  3.58           2\n",
      "69  1931  3.58           3\n",
      "70  1933  3.59           3\n",
      "71  1778  3.59           1\n",
      "72  1975  3.60           1\n",
      "73  1934  3.60           3\n",
      "74  2021  3.61           3\n",
      "75  2015  3.62           3\n",
      "76  1997  3.64           1\n",
      "77  2020  3.65           2\n",
      "78  1843  3.71           3\n",
      "79  1936  3.71           3\n",
      "80  1810  3.71           1\n",
      "81  1987  3.73           3\n",
      "82  1962  3.76           1\n",
      "83  2050  3.81           2\n",
      "\n",
      "[84 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Multiple_Linear_Regression_SAT_GPA.csv')\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "# Observe the data. \n",
    "# Here GPA = DV, SAT = IV and 'Rand 1,2,3' is a column containing random numbers between 1 to 3 assigned to each row. \n",
    "# This column value definitely doesnt impact the GPA score. \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the multiple regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the dependent and the independent variables. We have 2 explanatory variables - SAT and 'Rand1,2,3'\n",
    "Model looks like:    GPA = b0 + b1*SAT + b2*Rand1,2,3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df.GPA                          # Get the DV\n",
    "x1 = df[['SAT', 'Rand 1,2,3']]      # Here x1 is a dataframe containing 2 IV series. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    GPA   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.392\n",
      "Method:                 Least Squares   F-statistic:                     27.76\n",
      "Date:                Tue, 01 Jan 2019   Prob (F-statistic):           6.58e-10\n",
      "Time:                        16:35:45   Log-Likelihood:                 12.720\n",
      "No. Observations:                  84   AIC:                            -19.44\n",
      "Df Residuals:                      81   BIC:                            -12.15\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2960      0.417      0.710      0.480      -0.533       1.125\n",
      "SAT            0.0017      0.000      7.432      0.000       0.001       0.002\n",
      "Rand 1,2,3    -0.0083      0.027     -0.304      0.762      -0.062       0.046\n",
      "==============================================================================\n",
      "Omnibus:                       12.992   Durbin-Watson:                   0.948\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.364\n",
      "Skew:                          -0.731   Prob(JB):                     0.000280\n",
      "Kurtosis:                       4.594   Cond. No.                     3.33e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.33e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Note: We will use the library statsmodels to perform simple/multiple Linear regression. \n",
    "# General multiple regression equation: y_hat = beta0 + beta1.x1 + beta2.x2\n",
    "# By default, the statsmodels method: statsmodels.regression.linear_model.OLS does not include the INTERCEPT beta0. \n",
    "# We have to explicitly manually add one if required. \n",
    "# 'statsmodels' however provides a convenience function called 'add_constant()' that adds a constant column to input dataset.\n",
    "\n",
    "x = sm.add_constant(x1)\n",
    "results = sm.OLS(y,x).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretations\n",
    "1. The R-squared: 0.407.....which is not so great. \n",
    "2. The adjusted R-squared value: 0.392\n",
    "3. Hypothesis: \n",
    "        \n",
    "        H0: Regression coefficients = 0 i.e. b0=b1=b2=0 i.e. the regression coefficients are insignificant. \n",
    "        H1: Regressions coefficients != 0 i.e. b0 != b1 != b2 !=0 i.e. the regression coefficients are significant. \n",
    "        \n",
    "4. The regression coefficients: \n",
    "        b0: 0.2960  ....constant\n",
    "        b1: 0.0017\n",
    "        b2: -0.0083\n",
    "        \n",
    "5. The p-values: \n",
    "        Rule: The IV is a significant contributor in explaining the variability in the DV, if the p-value < 0.05. \n",
    "        In other words...for a coefficient to be STATISTICALLY SIGNIFICANT, the p-value should be less than 0.05. \n",
    "        \n",
    "        In our case, the p-value corresponding to the IV 'Rule 1,2,3' is 0.762 > 0.05 i.e. we cannot reject the NULL Hypothesis \n",
    "        i.e. we accept the NULL Hypothesis. The variable 'Rand 1,2,3' is STATISTICALLY INSIGNIFICANT and is useless and thus \n",
    "        should be dropped.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess the overall significance of the model - using F-statistics. \n",
    "\n",
    "### Just as the:\n",
    "### z-statistic follows a Std Normal Distribution.\n",
    "### t-statistic follows a student's t-distribution.\n",
    "### F-statistics follows a F distribution.\n",
    "\n",
    "#### F-test:\n",
    "    H0: All beta's are 0 i.e. beta1 = beta2 = beta3 .....= betak = 0 i.e. None of the IV are statistically significant.  \n",
    "    H1: Atleast one of the beta is non-zero.\n",
    "#### In our case:\n",
    "    F-statistic:  27.76\n",
    "    Prob (F-statistic): 6.58e-10   .... (The p-value corresponding to this F-statistic). Here the p-value is very \n",
    "    low..practically 0.000 which is less tha 0.05. Thus the OVERALL MODEL IS SIGNIFICANT. \n",
    "\n",
    "### Thumbrule: Lower the F-statistic, closer to the Non-Significant model. F-statistic thus plays an important role, when we have to compare 2 models. \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
