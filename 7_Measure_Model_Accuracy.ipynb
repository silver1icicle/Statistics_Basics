{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of this notebook is to demonstrate the way to compute model accuracy. We will extend the same example of Logistic Regression with Binary predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set()                             # Apply a skin to matplotlib plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SAT Admitted  Gender\n",
      "0    1363       No    Male\n",
      "1    1792      Yes  Female\n",
      "2    1954      Yes  Female\n",
      "3    1653       No    Male\n",
      "4    1593       No    Male\n",
      "5    1755      Yes  Female\n",
      "6    1775      Yes  Female\n",
      "7    1887      Yes  Female\n",
      "8    1893      Yes  Female\n",
      "9    1580       No    Male\n",
      "10   1857      Yes  Female\n",
      "11   1880      Yes  Female\n",
      "12   1664      Yes  Female\n",
      "13   1364       No    Male\n",
      "14   1693       No    Male\n",
      "15   1850      Yes  Female\n",
      "16   1633       No    Male\n",
      "17   1634       No    Male\n",
      "18   1636      Yes  Female\n",
      "19   1855      Yes  Female\n",
      "20   1987      Yes  Female\n",
      "21   1997      Yes    Male\n",
      "22   1422       No  Female\n",
      "23   1508       No  Female\n",
      "24   1720      Yes  Female\n",
      "25   1879      Yes    Male\n",
      "26   1634      Yes  Female\n",
      "27   1802      Yes    Male\n",
      "28   1849      Yes  Female\n",
      "29   1764      Yes  Female\n",
      "..    ...      ...     ...\n",
      "138  1412       No  Female\n",
      "139  1557       No    Male\n",
      "140  1821      Yes    Male\n",
      "141  1760      Yes  Female\n",
      "142  1685      Yes    Male\n",
      "143  1773      Yes  Female\n",
      "144  1826      Yes  Female\n",
      "145  1565       No  Female\n",
      "146  1510       No    Male\n",
      "147  1374       No    Male\n",
      "148  1402       No    Male\n",
      "149  1702      Yes    Male\n",
      "150  1956      Yes  Female\n",
      "151  1933      Yes    Male\n",
      "152  1832      Yes    Male\n",
      "153  1893      Yes    Male\n",
      "154  1831      Yes  Female\n",
      "155  1487       No    Male\n",
      "156  2041      Yes  Female\n",
      "157  1850      Yes    Male\n",
      "158  1555       No  Female\n",
      "159  2020      Yes  Female\n",
      "160  1593       No    Male\n",
      "161  1934      Yes  Female\n",
      "162  1808      Yes    Male\n",
      "163  1722      Yes  Female\n",
      "164  1750      Yes    Male\n",
      "165  1555       No    Male\n",
      "166  1524       No    Male\n",
      "167  1461       No    Male\n",
      "\n",
      "[168 rows x 3 columns]\n",
      "Index(['SAT', 'Admitted', 'Gender'], dtype='object')\n",
      "(168, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Binary predictors.csv')\n",
    "print(df)                                      # View the DataFrame\n",
    "print(df.columns)                              # ['SAT', 'Admitted', 'Gender']\n",
    "print(df.shape)                                # 168 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the mapping of categorical variables. \n",
    "DV: Admitted [Categorical/ nonmetric]\n",
    "\n",
    "IV: SAT [Numeric/metric] + Gender [Categorical/ nonmetric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640215661424\n",
      "2640215824928\n",
      "['No' 'Yes']\n",
      "['Male' 'Female']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1954</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1755</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1775</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1893</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1855</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1422</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1879</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1634</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1764</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1956</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2041</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SAT  Admitted  Gender\n",
       "0    1363         0       0\n",
       "1    1792         1       1\n",
       "2    1954         1       1\n",
       "3    1653         0       0\n",
       "4    1593         0       0\n",
       "5    1755         1       1\n",
       "6    1775         1       1\n",
       "7    1887         1       1\n",
       "8    1893         1       1\n",
       "9    1580         0       0\n",
       "10   1857         1       1\n",
       "11   1880         1       1\n",
       "12   1664         1       1\n",
       "13   1364         0       0\n",
       "14   1693         0       0\n",
       "15   1850         1       1\n",
       "16   1633         0       0\n",
       "17   1634         0       0\n",
       "18   1636         1       1\n",
       "19   1855         1       1\n",
       "20   1987         1       1\n",
       "21   1997         1       0\n",
       "22   1422         0       1\n",
       "23   1508         0       1\n",
       "24   1720         1       1\n",
       "25   1879         1       0\n",
       "26   1634         1       1\n",
       "27   1802         1       0\n",
       "28   1849         1       1\n",
       "29   1764         1       1\n",
       "..    ...       ...     ...\n",
       "138  1412         0       1\n",
       "139  1557         0       0\n",
       "140  1821         1       0\n",
       "141  1760         1       1\n",
       "142  1685         1       0\n",
       "143  1773         1       1\n",
       "144  1826         1       1\n",
       "145  1565         0       1\n",
       "146  1510         0       0\n",
       "147  1374         0       0\n",
       "148  1402         0       0\n",
       "149  1702         1       0\n",
       "150  1956         1       1\n",
       "151  1933         1       0\n",
       "152  1832         1       0\n",
       "153  1893         1       0\n",
       "154  1831         1       1\n",
       "155  1487         0       0\n",
       "156  2041         1       1\n",
       "157  1850         1       0\n",
       "158  1555         0       1\n",
       "159  2020         1       1\n",
       "160  1593         0       0\n",
       "161  1934         1       1\n",
       "162  1808         1       0\n",
       "163  1722         1       1\n",
       "164  1750         1       0\n",
       "165  1555         0       0\n",
       "166  1524         0       0\n",
       "167  1461         0       0\n",
       "\n",
       "[168 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "print(id(df))                # 2133977826808\n",
    "print(id(df_new))            # 2133977825352\n",
    "\n",
    "\n",
    "# The DV- \"Admitted\" and the IV- \"Gender\" are categorical\n",
    "# Lets first see the number of unique values in each of these columns. \n",
    "print(df_new.Admitted.unique())     # ['No' 'Yes'] - Only 2 values\n",
    "print(df_new.Gender.unique())       # ['Male' 'Female'] - Only 2 values\n",
    "\n",
    "# Map it suitably\n",
    "df_new.Admitted = df_new.Admitted.map({'Yes': 1, 'No': 0})\n",
    "df_new.Gender = df_new.Gender.map({'Female' : 1, 'Male' : 0})\n",
    "df_new\n",
    "\n",
    "# In statistical terminology, 'Male' is the baseline or the reference group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare the IV and DV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     const   SAT  Gender\n",
      "0      1.0  1363       0\n",
      "1      1.0  1792       1\n",
      "2      1.0  1954       1\n",
      "3      1.0  1653       0\n",
      "4      1.0  1593       0\n",
      "5      1.0  1755       1\n",
      "6      1.0  1775       1\n",
      "7      1.0  1887       1\n",
      "8      1.0  1893       1\n",
      "9      1.0  1580       0\n",
      "10     1.0  1857       1\n",
      "11     1.0  1880       1\n",
      "12     1.0  1664       1\n",
      "13     1.0  1364       0\n",
      "14     1.0  1693       0\n",
      "15     1.0  1850       1\n",
      "16     1.0  1633       0\n",
      "17     1.0  1634       0\n",
      "18     1.0  1636       1\n",
      "19     1.0  1855       1\n",
      "20     1.0  1987       1\n",
      "21     1.0  1997       0\n",
      "22     1.0  1422       1\n",
      "23     1.0  1508       1\n",
      "24     1.0  1720       1\n",
      "25     1.0  1879       0\n",
      "26     1.0  1634       1\n",
      "27     1.0  1802       0\n",
      "28     1.0  1849       1\n",
      "29     1.0  1764       1\n",
      "..     ...   ...     ...\n",
      "138    1.0  1412       1\n",
      "139    1.0  1557       0\n",
      "140    1.0  1821       0\n",
      "141    1.0  1760       1\n",
      "142    1.0  1685       0\n",
      "143    1.0  1773       1\n",
      "144    1.0  1826       1\n",
      "145    1.0  1565       1\n",
      "146    1.0  1510       0\n",
      "147    1.0  1374       0\n",
      "148    1.0  1402       0\n",
      "149    1.0  1702       0\n",
      "150    1.0  1956       1\n",
      "151    1.0  1933       0\n",
      "152    1.0  1832       0\n",
      "153    1.0  1893       0\n",
      "154    1.0  1831       1\n",
      "155    1.0  1487       0\n",
      "156    1.0  2041       1\n",
      "157    1.0  1850       0\n",
      "158    1.0  1555       1\n",
      "159    1.0  2020       1\n",
      "160    1.0  1593       0\n",
      "161    1.0  1934       1\n",
      "162    1.0  1808       0\n",
      "163    1.0  1722       1\n",
      "164    1.0  1750       0\n",
      "165    1.0  1555       0\n",
      "166    1.0  1524       0\n",
      "167    1.0  1461       0\n",
      "\n",
      "[168 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "y = df_new.Admitted\n",
    "x1 = df_new[['SAT', 'Gender']]\n",
    "# Since Statsmodels module doesnt consider the constant term b0, in regression, we need to make explicit provision for it, \n",
    "# by adding a dummy column 'const' for x0 which comprises of only 1's. \n",
    "x = sm.add_constant(x1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.120117\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Admitted</td>     <th>  No. Observations:  </th>  <td>   168</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   165</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 07 Jan 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.8249</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:35:39</td>     <th>  Log-Likelihood:    </th> <td> -20.180</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -115.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>5.118e-42</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>  -68.3489</td> <td>   16.454</td> <td>   -4.154</td> <td> 0.000</td> <td> -100.598</td> <td>  -36.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAT</th>    <td>    0.0406</td> <td>    0.010</td> <td>    4.129</td> <td> 0.000</td> <td>    0.021</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th> <td>    1.9449</td> <td>    0.846</td> <td>    2.299</td> <td> 0.022</td> <td>    0.287</td> <td>    3.603</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.27 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Admitted   No. Observations:                  168\n",
       "Model:                          Logit   Df Residuals:                      165\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 07 Jan 2019   Pseudo R-squ.:                  0.8249\n",
       "Time:                        15:35:39   Log-Likelihood:                -20.180\n",
       "converged:                       True   LL-Null:                       -115.26\n",
       "                                        LLR p-value:                 5.118e-42\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -68.3489     16.454     -4.154      0.000    -100.598     -36.100\n",
       "SAT            0.0406      0.010      4.129      0.000       0.021       0.060\n",
       "Gender         1.9449      0.846      2.299      0.022       0.287       3.603\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.27 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_log = sm.Logit(y, x)\n",
    "results_log = reg_log.fit()\n",
    "results_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference: \n",
    "1. The model is significant, as the LLR p-value is very very low i.e. 0.000.\n",
    "2. Also the \"Gender\" variable is significant, as its p-value = 0.022 which is less than 0.05. \n",
    "3. The exact model is:\n",
    "            => ln(odds) = -68.3489 + 0.0406*SAT + 1.9449*Gender\n",
    "  \n",
    "  Assume that there are 2 students who got the same SAT score\n",
    "  \n",
    "            i.e. SAT2 - SAT1 = 0\n",
    "  Assume that there is a one unit change in the Gender of the students who got the same SAT score i.e. One is M while other is F\n",
    "            Gender2 = 1 (i.e. Female) and Gender1 = 0 (i.e. Male)\n",
    "  \n",
    "  Interpretation of Logistic regression variables isnt direct. We have to follow the difference method. \n",
    "           \n",
    "           => ln(odds2) = -68.3489 + 0.0406*SAT2 + 1.9449*Gender2\n",
    "              ln(odds1) = -68.3489 + 0.0406*SAT1 + 1.9449*Gender1\n",
    "             -            +        -             - \n",
    "             ------------------------------------------------------------------------\n",
    "             ln(odds2) - ln(odds1) = 0.0406(SAT2 - SAT1) + 1.9449(Gender2 - Gender1)\n",
    "             ------------------------------------------------------------------------\n",
    "             \n",
    "           => ln(odds2/odds1) = 1.9449\n",
    "           => odds2/odds1 = e^1.9449\n",
    "           => odds2/odds1 = 6.9929 ~= 7.0\n",
    "           => odds_female/odds_male = 7.0\n",
    "           => odds_female = 7.0 * odds_male\n",
    "           \n",
    "  Conclusion: \n",
    "      odds of the female getting admitted is 7.0 times the odds of a male getting admitted, given the same SAT score. In other words, the chance of females getting admitted is more than the chance of the male getting admitted. This however is not true in real life, as universities do have fixed quotas for each gender. \n",
    "             \n",
    "             \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One quick way to comment on the model accuracy is to refer to the pseudo-R squared value. However if we need a precise estimate of the model accuracy, we follow the below procedure:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00, 1.00, 1.00, 0.23, 0.02, 0.99, 1.00, 1.00, 1.00, 0.01, 1.00,\n",
       "       1.00, 0.76, 0.00, 0.60, 1.00, 0.11, 0.12, 0.51, 1.00, 1.00, 1.00,\n",
       "       0.00, 0.01, 0.97, 1.00, 0.48, 0.99, 1.00, 0.99, 0.00, 0.83, 0.25,\n",
       "       1.00, 1.00, 1.00, 0.31, 1.00, 0.23, 0.00, 0.02, 0.45, 1.00, 0.00,\n",
       "       0.99, 0.00, 0.99, 0.00, 0.00, 0.01, 0.00, 1.00, 0.92, 0.02, 1.00,\n",
       "       0.00, 0.37, 0.98, 0.12, 1.00, 0.00, 0.78, 1.00, 1.00, 0.98, 0.00,\n",
       "       0.00, 0.00, 1.00, 0.00, 0.78, 0.12, 0.00, 0.99, 1.00, 1.00, 0.00,\n",
       "       0.30, 1.00, 1.00, 0.00, 1.00, 1.00, 0.85, 1.00, 1.00, 0.00, 1.00,\n",
       "       1.00, 0.89, 0.83, 0.00, 0.98, 0.97, 0.00, 1.00, 1.00, 0.03, 0.99,\n",
       "       0.96, 1.00, 0.00, 1.00, 0.01, 0.01, 1.00, 1.00, 1.00, 0.00, 0.00,\n",
       "       0.02, 0.33, 0.00, 1.00, 0.09, 0.00, 0.97, 0.00, 0.75, 1.00, 1.00,\n",
       "       0.01, 0.01, 0.00, 1.00, 0.00, 0.99, 0.57, 0.54, 0.87, 0.83, 0.00,\n",
       "       1.00, 0.00, 0.00, 0.00, 1.00, 0.04, 0.00, 0.01, 1.00, 0.99, 0.52,\n",
       "       1.00, 1.00, 0.05, 0.00, 0.00, 0.00, 0.68, 1.00, 1.00, 1.00, 1.00,\n",
       "       1.00, 0.00, 1.00, 1.00, 0.04, 1.00, 0.02, 1.00, 0.99, 0.97, 0.94,\n",
       "       0.01, 0.00, 0.00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1] Our model predicts values i.e. actual numbers. In order to determine the predicted values for the given inputs, \n",
    "# statsmodels module provides us the method predict(). \n",
    "# Our model is stored in the variable results_log\n",
    "\n",
    "results_log.predict()     # These are the values predicted by our model, for the inputs we provided. \n",
    "\n",
    "# For better reading...apply a formatting of rounding upto 2 decimal places. \n",
    "np.set_printoptions(formatter = {'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "results_log.predict()     # These are the values predicted by our model, for the inputs we provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference: \n",
    "Observe that the values returned by our model are infact the probabilties and therefore they lie between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2] Now consider the ACTUAL values of the DV we had since the onset:\n",
    "np.array(df_new.Admitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.00, 5.00],\n",
       "       [4.00, 90.00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strategy: if 80% of the predicted values COINCIDE with the actual values, we say that the model has an 80% accuracy, which is \n",
    "# pretty good. \n",
    "# STEP 3] Compare the PREDICTED values with the ACTUAL values by constructing the CONFUSION MATRIX. \n",
    "# Confusion matrix in statsmodels is computed using the method pred_table()\n",
    "results_log.pred_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         69.0          5.0\n",
       "Actual 1          4.0         90.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets format the output for clearer understanding\n",
    "df_confMat = pd.DataFrame(results_log.pred_table())\n",
    "df_confMat.columns = ['Predicted 0', 'Predicted 1']\n",
    "df_confMat = df_confMat.rename(index = {0: 'Actual 0', 1: 'Actual 1'})\n",
    "df_confMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference:\n",
    "1. This is the CONFUSION MATRIX, comprising of the comparison results of the actual and the predicted values. \n",
    "2. Reading the CONFUSION MATRIX:\n",
    "           2.1] For 69 observations the model predicted 0 when it actually was 0. \n",
    "           2.2] For 90 observations the model predicted 1 when it actually was 1. \n",
    "               Both [2.1] and [2.2] refer to the cases where the model predicted well. However, \n",
    "          \n",
    "           2.3] In 4 cases the model predicted 0 when the actual was 1. \n",
    "           2.4] In 5 cases the model predicted 1 when the actual was 0. \n",
    "               Both [2.3] and [2.4] refer to the cases where the model got confused.\n",
    "\n",
    "3. Computing accuracy:\n",
    "                    => Total observations = 168\n",
    "                    => Cases when model predicted as expected = 159\n",
    "                    Accuracy = (159/168) * 100 = 94.64%.....pretty good!!\n",
    "   \n",
    "   Given that accuracy, our model seems pretty good in doing classification. \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted 0  Predicted 1\n",
      "Actual 0         69.0          5.0\n",
      "Actual 1          4.0         90.0\n",
      "\n",
      "Training Accuracy:----------------------> 0.9464285714285714\n"
     ]
    }
   ],
   "source": [
    "# Code to compute percentage accuracy\n",
    "print(df_confMat)                             # <DataFrame>\n",
    "arr_confMat = np.array(df_confMat)            # <numpy.ndarray>\n",
    "\n",
    "train_accuracy = (arr_confMat[0,0] + arr_confMat[1,1])/arr_confMat.sum()\n",
    "print()\n",
    "print(\"Training Accuracy:---------------------->\", train_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
