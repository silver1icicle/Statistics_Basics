{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas: to_datetime()\n",
    "### One of the most common problem in data analysis is the lack of uniformity in the structure of the input data. \n",
    "### For e.g. Jan 12, 2019 can be represented in all the following formats:\n",
    "### 1. 2019-01-12 \n",
    "### 2. Jan 12, 2019\n",
    "### 3. 01/12/2019\n",
    "### 4. 2019.01.12\n",
    "### 5. 2019/01/12\n",
    "### 6. 20190112\n",
    "\n",
    "## Thus one of the most crucial task is the data pre-processing where in we standardize the date format to a uniform pattern. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-12', '2019-01-12', '2019-01-12', '2019-01-12',\n",
       "               '2019-01-12', '2019-01-12'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dates = ['2019-01-12', 'Jan 12, 2019', '01/12/2019', '2019.01.12', '2019/01/12', '20190112']   # All possible date formats\n",
    "\n",
    "# Standardize the dates using pandas to_datetime()\n",
    "pd.to_datetime(dates)\n",
    "\n",
    "# Observe that all dates are mapped to a uniform pattern  of YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Dates with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-12 14:30:00', '2019-01-12 14:30:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets say we are talking about 12th Jan, 2019 2:30PM\n",
    "dates = ['2019-01-12 2:30:00 PM', 'Jan 12, 2019 14:30:00']   # All possible date and time formats\n",
    "pd.to_datetime(dates)\n",
    "\n",
    "# Observe that the datetime stamps are standardized to the format: YYYY-MM-DD HH:MM:SS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing dates as per the country US/ Europe\n",
    "### For e.g. the Jan 12, 2019 is represented in following ways:\n",
    "### USA: 01/12/2019    [MM / DD / YYYY - pandas's default]\n",
    "### UK  : 12/01/2019     [DD / MM / YYYY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-12 00:00:00')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets say we wish to represent the UK date in US pattern. \n",
    "pd.to_datetime('12/01/2019', dayfirst=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Date format: Assume that your custom date uses # as the date delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-12 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The date Jan 12, 2019 in custom format is represented as 01#12#2019. \n",
    "# Standardize this.\n",
    "pd.to_datetime('01#12#2019', format='%m#%d#%Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the dates while ignoring the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-01-12', 'Jan 12, 2019', '01/12/2019', '2019.01.12',\n",
       "       '2019/01/12', '20190112', 'APPLE'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets say our dates are in varied formats of which few formats are absolute junk. \n",
    "# The default handling of the to_datetime() for such junk values is to throw an exception. However if we want to_datetime() \n",
    "# to simple ignore such values:\n",
    "dates = ['2019-01-12', 'Jan 12, 2019', '01/12/2019', '2019.01.12', '2019/01/12', '20190112', 'APPLE']   \n",
    "\n",
    "# Standardize the dates using pandas to_datetime()\n",
    "pd.to_datetime(dates, errors='ignore')\n",
    "\n",
    "# Observe: the Junk value was ignored! But the standardization of the remaining dates was skipped too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-12', '2019-01-12', '2019-01-12', '2019-01-12',\n",
       "               '2019-01-12', '2019-01-12',        'NaT'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To selectively ignore the junk value while standardizing the remaining values:\n",
    "dates = ['2019-01-12', 'Jan 12, 2019', '01/12/2019', '2019.01.12', '2019/01/12', '20190112', 'APPLE']   \n",
    "\n",
    "# Standardize the dates using pandas to_datetime()\n",
    "pd.to_datetime(dates, errors='coerce')\n",
    "\n",
    "# Observe: The remaining dates are standardized while the junk value is marked as 'NaT' i.e. 'Not a Timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Handling UNIX time or epoch time\n",
    "The UNIX time is the number of seconds that have passed since, Jan 01, 1970 00:00:00 UTC. \n",
    "The Epoch time 1547551766 is equivalent to [01/15/2019 11:29:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "2019-01-15 11:29:26\n",
      "\n",
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "DatetimeIndex(['2019-01-15 11:29:26'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "[1547551766000000000]\n"
     ]
    }
   ],
   "source": [
    "t = 1547551766                                                         # These are the number of seconds since Jan 01, 1970\n",
    "\n",
    "# Converting epoch to Timestamp\n",
    "t_conv = pd.to_datetime(t, unit='s')                                   # Specify the unit as 'seconds'\n",
    "print(type(t_conv))                                                    # [Timestamp]\n",
    "print(t_conv)\n",
    "\n",
    "print()\n",
    "# Converting epoch to DateTimeIndex \n",
    "t_conv = pd.to_datetime([t], unit='s')\n",
    "print(type(t_conv))                                                    # [DatetimeIndex] - Simply supply epoch time as array []\n",
    "print(t_conv)\n",
    "\n",
    "print()\n",
    "# Converting DatetimeTindex back to epoch\n",
    "print(t_conv.view('int64'))                                            # [1547551766000000000] Its in nanosecondss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
